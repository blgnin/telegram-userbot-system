"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ—á–∏ –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤
–≤ —Å–∏—Å—Ç–µ–º—É –±–æ—Ç–æ–≤ –¥–ª—è –±–æ–ª–µ–µ —á–µ–ª–æ–≤–µ—á–Ω–æ–≥–æ –æ–±—â–µ–Ω–∏—è
"""
import json
import random
import os
from typing import Dict, List, Optional
from pathlib import Path

class NaturalSpeechHandler:
    def __init__(self, natural_speech_dir: str = None):
        if natural_speech_dir is None:
            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
            current_dir = Path(__file__).parent
            self.natural_speech_dir = str(current_dir / "natural_speech")
        else:
            self.natural_speech_dir = natural_speech_dir
        self.speech_data = {}
        self.load_natural_speech_data()
        
    def load_natural_speech_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ—á–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        try:
            if not os.path.exists(self.natural_speech_dir):
                print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ {self.natural_speech_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ chat_parser.py")
                return
            
            categories = ['general', 'questions', 'statements', 'emotional', 'conversation_starters']
            
            for category in categories:
                file_path = os.path.join(self.natural_speech_dir, f"{category}.json")
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        self.speech_data[category] = data.get('messages', [])
                        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.speech_data[category])} —Å–æ–æ–±—â–µ–Ω–∏–π: {category}")
                else:
                    self.speech_data[category] = []
                    print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            
            total_messages = sum(len(messages) for messages in self.speech_data.values())
            print(f"üìä –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {total_messages}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ—á–∏: {e}")
            self.speech_data = {cat: [] for cat in ['general', 'questions', 'statements', 'emotional', 'conversation_starters']}
    
    def get_natural_response(self, message: str, bot_name: str, context: str = "") -> Optional[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤
        """
        try:
            message_lower = message.lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            response_category = self._determine_response_category(message_lower, context)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –æ—Ç–≤–µ—Ç—ã
            candidate_responses = self.speech_data.get(response_category, [])
            
            if not candidate_responses:
                # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –ø—Ä–æ–±—É–µ–º –æ–±—â–∏–µ
                candidate_responses = self.speech_data.get('general', [])
            
            if not candidate_responses:
                return None
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ —Ç–µ–º–µ –ø–æ–µ–∑–¥–æ–∫/–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            relevant_responses = self._filter_relevant_responses(candidate_responses, message_lower, context)
            
            if not relevant_responses:
                # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã
                relevant_responses = [resp for resp in candidate_responses if len(resp) < 50][:10]
            
            if not relevant_responses:
                return None
            
            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–≤–µ—Ç –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –µ–≥–æ –ø–æ–¥ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            natural_response = random.choice(relevant_responses)
            adapted_response = self._adapt_response_to_character(natural_response, bot_name)
            
            return adapted_response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
            return None
    
    def _filter_relevant_responses(self, responses: List[str], message_lower: str, context: str) -> List[str]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ —Ç–µ–º–µ –ø–æ–µ–∑–¥–æ–∫ –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        travel_keywords = [
            # –ü–æ–µ–∑–¥–∫–∏ –∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç
            '–ø–æ–µ–∑–¥–∫–∞', '–ø–æ–µ–∑–¥–∫–∏', '–µ—Ö–∞—Ç—å', '–µ–¥–µ–º', '–µ–∑–¥–∏—Ç—å', '–¥–æ—Ä–æ–≥–∞', '–ø—É—Ç—å', '–º–∞—Ä—à—Ä—É—Ç',
            '–≤–æ–¥–∏—Ç–µ–ª—å', '–ø–∞—Å—Å–∞–∂–∏—Ä', '–º–∞—à–∏–Ω–∞', '–∞–≤—Ç–æ', '—Ç–∞–∫—Å–∏', '—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä', '–ø–æ–ø—É—Ç–∫–∞',
            '–∞–≤—Ç–æ–±—É—Å', '–ø–æ–µ–∑–¥', '—Å–∞–º–æ–ª–µ—Ç', '–º–µ—Ç—Ä–æ', '—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–ø–µ—Ä–µ–µ–∑–¥',
            # –¶–µ–Ω—ã –∏ –æ–ø–ª–∞—Ç–∞
            '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ç–∞—Ä–∏—Ñ', '–¥–µ–Ω—å–≥–∏', '—Ä—É–±–ª', '–µ–≤—Ä–æ', '–¥–æ–ª–ª–∞—Ä', 
            '–¥–µ—à–µ–≤–æ', '–¥–æ—Ä–æ–≥–æ', '—Å–∫–∏–¥–∫–∞', '–∞–∫—Ü–∏—è', '–æ–ø–ª–∞—Ç–∞', '–∫–∞—Ä—Ç–∞', '–Ω–∞–ª–∏—á–Ω—ã–µ',
            # –í—Ä–µ–º—è –∏ —Å–∫–æ—Ä–æ—Å—Ç—å
            '–≤—Ä–µ–º—è', '–±—ã—Å—Ç—Ä–æ', '–¥–æ–ª–≥–æ', '—á–∞—Å', '–º–∏–Ω—É—Ç', '—É—Ç—Ä–æ–º', '–≤–µ—á–µ—Ä–æ–º', 
            '—Å—Ä–æ—á–Ω–æ', '–º–µ–¥–ª–µ–Ω–Ω–æ', '–æ–ø–æ–∑–¥–∞—Ç—å', '—É—Å–ø–µ—Ç—å', '–≤–æ–≤—Ä–µ–º—è',
            # –ú–µ—Å—Ç–∞ –∏ –ª–æ–∫–∞—Ü–∏–∏
            '–≥–æ—Ä–æ–¥', '–∞—ç—Ä–æ–ø–æ—Ä—Ç', '–≤–æ–∫–∑–∞–ª', '—Ü–µ–Ω—Ç—Ä', '—Ä–∞–π–æ–Ω', '–∞–¥—Ä–µ—Å', '–º–µ—Å—Ç–æ',
            '–¥–æ–º', '—Ä–∞–±–æ—Ç–∞', '–æ—Ñ–∏—Å', '–º–∞–≥–∞–∑–∏–Ω', '–±–æ–ª—å–Ω–∏—Ü–∞', '–æ—Ç–µ–ª—å',
            # –ö–∞—á–µ—Å—Ç–≤–æ —Å–µ—Ä–≤–∏—Å–∞
            '—É–¥–æ–±–Ω–æ', '–∫–æ–º—Ñ–æ—Ä—Ç', '–±–µ–∑–æ–ø–∞—Å–Ω–æ', '–Ω–∞–¥–µ–∂–Ω–æ', '–∫–∞—á–µ—Å—Ç–≤–æ', '—Å–µ—Ä–≤–∏—Å',
            '–æ—Ç–∑—ã–≤', '—Ä–µ–π—Ç–∏–Ω–≥', '—Ä–µ–∫–æ–º–µ–Ω–¥—É—é', '—Å–æ–≤–µ—Ç—É—é', '—Ö–æ—Ä–æ—à–∏–π', '–ø–ª–æ—Ö–æ–π',
            # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
            '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '–∞–ø–ø–∫–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', '—Ç–µ–ª–µ—Ñ–æ–Ω', '–∑–∞–∫–∞–∑', '–±—Ä–æ–Ω—å',
            '–∫–Ω–æ–ø–∫–∞', '—ç–∫—Ä–∞–Ω', '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å', '—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ', '—Å–º—Å', '–∑–≤–æ–Ω–æ–∫',
            # GO-—Å–µ—Ä–≤–∏—Å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞
            'gominiapp', '–≥–æ–º–∏–Ω–∏', '–≥–æ —Å–µ—Ä–≤–∏—Å', '—Ç–æ–∫–µ–Ω', '–ø—Ä–µ–º–∏—É–º', '—Ä–µ–π—Ç–∏–Ω–≥',
            '–ø–æ–ø—É—Ç—á–∏–∫', 'blablacar', '–±–ª–∞–±–ª–∞–∫–∞—Ä', '–º–∏–Ω–∏-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'telegram',
            '–±–æ—Ç', '—á–∞—Ç', '—Å–æ–æ–±—â–µ–Ω–∏–µ', '–æ—Å—Ç–∞–Ω–æ–≤–∫–∞', '–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π', '—Ç–æ—á–∫–∞',
            '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è', '–ø—Ä–æ—Ñ–∏–ª—å', '–Ω–∞—Å—Ç—Ä–æ–π–∫–∏', '—Ä–æ–ª—å', '—Å—Ç–∞—Ç—É—Å'
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤
        relevant = []
        for response in responses:
            response_lower = response.lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            has_travel_words = any(keyword in response_lower for keyword in travel_keywords)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É (–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ —Å—Ä–µ–¥–Ω–∏–µ –æ—Ç–≤–µ—Ç—ã)
            is_good_length = 10 <= len(response) <= 100
            
            # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–µ –æ—Ç–≤–µ—Ç—ã (–Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–æ–µ–∑–¥–∫–∞–º–∏)
            bad_patterns = [
                '–∫–∏–ø—Å', '–∫–∏–ø', '—Å—Ç—Ä–∞–Ω–Ω–æ', '–Ω–µ–ø–æ–Ω—è—Ç–Ω–æ', '—Ö–∑', '–Ω–µ –∑–Ω–∞—é —á—Ç–æ —ç—Ç–æ',
                '–º—É–∑—ã–∫–∞', '–ø–µ—Å–Ω—è', '—Ñ–∏–ª—å–º', '–∫–∏–Ω–æ', '–∏–≥—Ä–∞', '—Å–ø–æ—Ä—Ç', '—Ñ—É—Ç–±–æ–ª',
                '–µ–¥–∞', '–≥–æ—Ç–æ–≤–∏—Ç—å', '—Ä–µ—Ü–µ–ø—Ç', '—Ä–µ—Å—Ç–æ—Ä–∞–Ω', '–∫–∞—Ñ–µ', '–±–∞—Ä',
                '—Ä–∞–±–æ—Ç–∞ –Ω–µ –ø–æ —Ç–µ–º–µ', '—É—á–µ–±–∞', '—à–∫–æ–ª–∞', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '—ç–∫–∑–∞–º–µ–Ω',
                '–ø–æ–≥–æ–¥–∞ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫', '–¥–æ–∂–¥—å –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞', '—Å–Ω–µ–≥ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞',
                'zara', 'bulevar', 'vlahoviƒáa', '–º–∞–≥–∞–∑–∏–Ω –æ–¥–µ–∂–¥—ã', '—à–æ–ø–∏–Ω–≥', '–ø–æ–∫—É–ø–∫–∏',
                '–≤–∏–∫–∏–ø–µ–¥–∏—è', 'wikipedia', '—Å—Å—ã–ª–∫–∞', '—Å–∞–π—Ç', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞',
                '–ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å', '–æ—Ç–Ω–æ—à–µ–Ω–∏—è –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞', '–ª—é–±–æ–≤—å –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞'
            ]
            has_bad_patterns = any(bad in response_lower for bad in bad_patterns)
            
            if (has_travel_words or is_good_length) and not has_bad_patterns:
                relevant.append(response)
        
        return relevant[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    
    def _determine_response_category(self, message_lower: str, context: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ - –≤–æ–ø—Ä–æ—Å, –æ—Ç–≤–µ—á–∞–µ–º —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
        if any(word in message_lower for word in ['—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '?']):
            return 'statements'
        
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ, –æ—Ç–≤–µ—á–∞–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        emotional_words = ['–∫—Ä—É—Ç–æ', '–æ—Ç–ª–∏—á–Ω–æ', '—Å—É–ø–µ—Ä', '–æ—Ñ–∏–≥–µ—Ç—å', '–≤–∞—É', '–±–ª–∏–Ω', '—á–µ—Ä—Ç', '–∫–∞–ø–µ—Ü', '–∂–µ—Å—Ç—å']
        if any(word in message_lower for word in emotional_words):
            return 'emotional'
        
        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–∞—á–∞–ª–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –æ—Ç–≤–µ—á–∞–µ–º –¥—Ä—É–∂–µ–ª—é–±–Ω–æ
        if any(word in message_lower for word in ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä', '—Å–∞–ª—é—Ç']):
            return 'conversation_starters'
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –æ–±—â–∏–µ –æ—Ç–≤–µ—Ç—ã
        return 'general'
    
    def _adapt_response_to_character(self, response: str, bot_name: str) -> str:
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –ø–æ–¥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±–æ—Ç–∞"""
        
        if "Leonardo" in bot_name:
            # Leonardo - –ø–∞—Å—Å–∞–∂–∏—Ä, –¥—É—à–Ω—ã–π, —ç–∫–æ–Ω–æ–º–Ω—ã–π
            response = self._add_leonardo_flavor(response)
        elif "Daniel" in bot_name:
            # Daniel - –≤–æ–¥–∏—Ç–µ–ª—å, —É–≤–µ—Ä–µ–Ω–Ω—ã–π, —Å Lexus
            response = self._add_daniel_flavor(response)
        elif "–ê–ª–µ–≤—Ç–∏–Ω–∞" in bot_name or "–∞–ª–µ–≤—Ç–∏–Ω–∞" in bot_name:
            # –ê–ª–µ–≤—Ç–∏–Ω–∞ - –∫—Ä–∏—Ç–∏–∫, –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è, –Ω–µ–¥–æ–≤–æ–ª—å–Ω–∞—è
            response = self._add_alevtina_flavor(response)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —Ä–∞–∑—É–º–Ω–æ–π –¥–ª–∏–Ω—ã (–º–∞–∫—Å–∏–º—É–º 150 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(response) > 150:
            sentences = response.split('.')
            if sentences:
                response = sentences[0] + '.'
        
        return response
    
    def _add_leonardo_flavor(self, response: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —á–µ—Ä—Ç—ã Leonardo –∫ –æ—Ç–≤–µ—Ç—É"""
        
        # –°–ª–æ–≤–∞—Ä—å –∑–∞–º–µ–Ω –¥–ª—è Leonardo (–ø–∞—Å—Å–∞–∂–∏—Ä, —ç–∫–æ–Ω–æ–º–Ω—ã–π)
        leonardo_replacements = {
            '–º–∞—à–∏–Ω–∞': '–ø–æ–ø—É—Ç–∫–∞',
            '–ø–æ–µ—Ö–∞–ª–∏': '–¥–æ–±–∏—Ä–∞–µ–º—Å—è',
            '–¥–æ—Ä–æ–≥–æ': '–¥–ª—è –º–µ–Ω—è –¥–æ—Ä–æ–≥–æ',
            '–∫–ª–∞—Å—Å–Ω–æ': '–Ω–æ—Ä–º, –Ω–æ –¥–æ—Ä–æ–≥–æ',
            '–æ—Ç–ª–∏—á–Ω–æ': '–Ω–µ–ø–ª–æ—Ö–æ, –µ—Å–ª–∏ –ø–æ –∫–∞—Ä–º–∞–Ω—É'
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã
        for old, new in leonardo_replacements.items():
            response = response.replace(old, new)
        
        return response
    
    def _add_daniel_flavor(self, response: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —á–µ—Ä—Ç—ã Daniel –∫ –æ—Ç–≤–µ—Ç—É"""
        
        # –°–ª–æ–≤–∞—Ä—å –∑–∞–º–µ–Ω –¥–ª—è Daniel (–≤–æ–¥–∏—Ç–µ–ª—å, —Å Lexus)
        daniel_replacements = {
            '–º–∞—à–∏–Ω–∞': 'Lexus',
            '—Ç–∞—á–∫–∞': 'Lexus',
            '–∞–≤—Ç–æ': 'Lexus'
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã
        for old, new in daniel_replacements.items():
            response = response.replace(old, new)
        
        return response
    
    def _add_alevtina_flavor(self, response: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —á–µ—Ä—Ç—ã –ê–ª–µ–≤—Ç–∏–Ω—ã –∫ –æ—Ç–≤–µ—Ç—É"""
        
        # –°–ª–æ–≤–∞—Ä—å –∑–∞–º–µ–Ω –¥–ª—è –ê–ª–µ–≤—Ç–∏–Ω—ã (–∫—Ä–∏—Ç–∏–∫, –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è)
        alevtina_replacements = {
            '—Ö–æ—Ä–æ—à–æ': '–Ω–æ—Ä–º–∞–ª—å–Ω–æ',
            '–æ—Ç–ª–∏—á–Ω–æ': '–Ω—É –∏ —á—Ç–æ',
            '—Å—É–ø–µ—Ä': '–Ω—É –¥–∞, –∫–æ–Ω–µ—á–Ω–æ',
            '–∫–ª–∞—Å—Å–Ω–æ': '–∞–≥–∞, –∫–∞–∫ –∂–µ',
            '–∫—Ä—É—Ç–æ': '–∏ —á—Ç–æ —Å —Ç–æ–≥–æ',
            '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ': '–Ω—É –∏ –¥–µ–ª–∞',
            '–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ': '–Ω—É –¥–∞, –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ'
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã
        for old, new in alevtina_replacements.items():
            response = response.replace(old, new)
        
        return response
    
    def get_conversation_starter(self, bot_name: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –Ω–∞—á–∞–ª–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
        starters = self.speech_data.get('conversation_starters', [])
        
        if not starters:
            # –ó–∞–ø–∞—Å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
            if "Leonardo" in bot_name:
                return "–ù–∞—Ä–æ–¥, –∫–∞–∫ –¥–µ–ª–∞ —Å –ø–æ–ø—É—Ç–∫–∞–º–∏?"
            elif "–ê–ª–µ–≤—Ç–∏–Ω–∞" in bot_name or "–∞–ª–µ–≤—Ç–∏–Ω–∞" in bot_name:
                return "–û–ø—è—Ç—å —á—Ç–æ-—Ç–æ –Ω–æ–≤–æ–µ –ø—Ä–∏–¥—É–º–∞–ª–∏? –ò —á—Ç–æ —ç—Ç–æ –∑–∞ —Ö–µ—Ä–Ω—è?"
            else:
                return "–†–µ–±—è—Ç, –∫—Ç–æ –∫—É–¥–∞ –µ–¥–µ—Ç?"
        
        starter = random.choice(starters)
        return self._adapt_response_to_character(starter, bot_name)
    
    def enhance_ai_response(self, ai_response: str, bot_name: str) -> str:
        """–£–ª—É—á—à–∞–µ—Ç AI –æ—Ç–≤–µ—Ç, –¥–æ–±–∞–≤–ª—è—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏"""
        try:
            # –ï—Å–ª–∏ AI –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, –∑–∞–º–µ–Ω—è–µ–º –µ–≥–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º
            formal_indicators = [
                '—è –¥—É–º–∞—é', '—Å—á–∏—Ç–∞—é —á—Ç–æ', '–ø–æ–ª–∞–≥–∞—é', '–º–Ω–µ –∫–∞–∂–µ—Ç—Å—è',
                '–ø–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é', '—Å –º–æ–µ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è'
            ]
            
            if any(indicator in ai_response.lower() for indicator in formal_indicators):
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
                natural_alternative = self.get_natural_response("", bot_name)
                if natural_alternative and len(natural_alternative) > 10:
                    return natural_alternative
            
            return ai_response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ AI –æ—Ç–≤–µ—Ç–∞: {e}")
            return ai_response
    
    def get_statistics(self) -> Dict[str, int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º"""
        return {category: len(messages) for category, messages in self.speech_data.items()}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª—è—Ö
natural_speech = NaturalSpeechHandler()